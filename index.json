[{"categories":["Systems"],"content":"Sometimes, it would be awfully convenient to grab the installer for the latest release of your favorite Github project directly from the command-line. And if it could incorporate awk, that would be great too.[1] Well, the following command-line is a pretty nifty template to do just that! You will need curl for this to work. Substitute in the user or organization name, the project’s name, and the desired file extension for the \u003cuser\u003e, \u003crepo\u003e, and \u003cextension\u003e fields respectively. Install the latest Github release $ curl -s https://api.github.com/repos/\u003cuser\u003e/\u003crepo\u003e/releases/latest | awk -F': ' '/browser_download_url/ \u0026\u0026 /\\.\u003cfile extension\u003e/ {gsub(/\"/, \"\", $(NF)); system(\"curl -LO \" $(NF))}' Here is a quick explanation. First, curl obtains the response from an HTTP GET request.footnote[RFC 2616] This response contains the URLs for the various artifacts for the latest release of the project. Next, awk processes the response, finding the line containing a download URL and matching the given file extension. It then removes the quotation marks surrounding the URL and downloads the file directly with curl. It’s also easy enough to modify the match pattern for the file extension to make it more specific if need be. The following example demonstrates this by fetching the latest Linux release zip file of the Ninja build system. Install the latest Ninja release $ curl -s https://api.github.com/repos/ninja-build/ninja/releases/latest | awk -F': ' '/browser_download_url/ \u0026\u0026 /linux\\.zip/ {gsub(/\"/, \"\", $(NF)); system(\"curl -LO \" $(NF))}' % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 637 100 637 0 0 1103 0 --:--:-- --:--:-- --:--:-- 1105 100 99913 100 99913 0 0 101k 0 --:--:-- --:--:-- --:--:-- 372kGithub Gist: One Liner to Download the Latest Release from Github Repo ↩ ","date":"2020-09-19","objectID":"/posts/fetch_latest_github_release/:0:0","tags":["awk","curl","git","Github"],"title":"One-liner to Fetch the Latest Github Release","uri":"/posts/fetch_latest_github_release/"},{"categories":["Systems"],"content":"Typing a password to login is repetitive enough, isn’t it? Entering the password for Sudo on the command-line can be downright irritating. If you don’t need that extra bit of protection, why enter your password more than you have to?[1] You can forever skip entering your sudo password, and it’s super easy and cross-platform. For whatever reason, I learned and forgot about doing this sometime ago, so here’s the gist. To disable password authentication for sudo for a user, in this case jordan, just run the following command.[2] $ echo \"jordan ALL=(ALL) NOPASSWD:ALL\" | sudo tee /etc/sudoers.d/jordan This just adds the line shown in [/etc/sudoers.d/jordan], which allows the given user to run any command with sudo without having to enter a password. /etc/sudoers.d/jordan jordan ALL=(ALL) NOPASSWD:ALLSecurity StackExchange: How secure is NOPASSWD in passwordless sudo mode? ↩Linuxize: How to Add User to Sudoers in Ubuntu - Adding User to the sudoers File ↩ ","date":"2020-09-19","objectID":"/posts/passwordless_sudo/:0:0","tags":["Linux","macOS","sudo"],"title":"Password-less Sudo","uri":"/posts/passwordless_sudo/"},{"categories":["Systems"],"content":"It’s Always Greener on the MATE Side While I was working on my recent post Virtualize Ubuntu Desktop on macOS with QEMU, I came across Canonical’s Multipass utility. Multipass makes it extremely simple to spin up Ubuntu instances on the fly whether your on Linux, macOS, and Windows. While your VM may not be as speedy as with QEMU, I would be remiss for not doing a quick write-up on this tool which makes it so easy to get up and running. The main caveat for Multipass is that it is only intended for running Ubuntu and neither other Linux distributions nor other operating systems. By default on macOS, Multipass uses Hyperkit behind the scenes.[1] ","date":"2020-09-13","objectID":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/:0:0","tags":["Homebrew","Linux","macOS","MacPorts","MATE","Multipass","Ubuntu","Ubuntu2004","Virtualization"],"title":"Easily Virtualize Ubuntu MATE on macOS with Multipass","uri":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/"},{"categories":["Systems"],"content":"TutorialSetting up a desktop with Multipass is briefly described here. This tutorial, in contrast, provides a complete set of instructions for configuring and running a Ubuntu MATE with Multipass on macOS. This tutorial assumes you have some experience with the command-line, virtualization, Ubuntu, and macOS. Steps Download the Multipass installer here.Run the installer and follow the directions to install Multipass.Create a new VM, allocating 2 CPU’s, 4 Gigabytes of RAM, and 50 Gigabytes of disk space. $ multipass launch -c 2 -m 4G -d 50G Launched: nurturing-eagleLaunch a shell in the guest. $ multipass shell nurturing-eagle Welcome to Ubuntu 20.04.1 LTS (GNU/Linux 5.4.0-47-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sun Sep 13 15:57:52 CDT 2020 System load: 0.45 Processes: 136 Usage of /: 2.6% of 48.29GB Users logged in: 0 Memory usage: 5% IPv4 address for enp0s2: 192.168.64.2 Swap usage: 0% 1 update can be installed immediately. 0 of these updates are security updates. To see these additional updates run: apt list --upgradable To run a command as administrator (user \"root\"), use \"sudo \u003ccommand\u003e\". See \"man sudo_root\" for details.Sync the package repositories. $ sudo apt updateUpdate any packages if needed. $ sudo apt upgradeInstall the Ubuntu MATE package and an RDP server. $ sudo apt install ubuntu-mate-desktop xrdp Note: To use the default desktop or other Ubuntu flavors, substitute the respective package. For example, substitute ubuntu-mate-desktop with ubuntu-desktop to install the standard Ubuntu desktop. Set a password for the default ubuntu. This password will be used when making an RDP connection. $ sudo passwd ubuntu New password: Retype new password: passwd: password updated successfullyBack on the host, determine the IP address of the guest for the RDP session. $ multipass info nurturing-eagle Name: nurturing-eagle State: Running IPv4: 192.168.64.2 Release: Ubuntu 20.04.1 LTS Image hash: 995771784f85 (Ubuntu 20.04 LTS) Load: 0.12 0.07 0.15 Disk usage: 4.3G out of 48.3G Memory usage: 204.7M out of 3.8G Here the IP address is 192.168.64.2. Install either Homebrew or MacPorts according to their installation instructions.Install FreeRDP with Homebrew or MacPorts. # Homebrew $ brew install xquartz $ brew install freerdp # MacPorts $ sudo port install FreeRDPConnect to the guest with FreeRDP.[2] $ xfreerdp /u:ubuntu /p:zorro /v:192.168.64.2 +clipboard This command-line simply initiates an RDP connection to the guest at IP 192.168.64.2 using the username ubuntu and the password zorro. The last flag enables a shared clipboard to allow copying and pasting between the host and virtual machine. ","date":"2020-09-13","objectID":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/:1:0","tags":["Homebrew","Linux","macOS","MacPorts","MATE","Multipass","Ubuntu","Ubuntu2004","Virtualization"],"title":"Easily Virtualize Ubuntu MATE on macOS with Multipass","uri":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/"},{"categories":["Systems"],"content":"ConclusionYou should now be able to create and access a virtualized Ubuntu desktop on macOS with Multipass. What’s more, it should be a piece of cake to transfer this method to running Ubuntu from a Windows or Linux host. Multipass Discourse: Installing Multipass on macOS ↩FreeRDP User Manual ↩ ","date":"2020-09-13","objectID":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/:2:0","tags":["Homebrew","Linux","macOS","MacPorts","MATE","Multipass","Ubuntu","Ubuntu2004","Virtualization"],"title":"Easily Virtualize Ubuntu MATE on macOS with Multipass","uri":"/posts/easily_virtualize_ubuntu_mate_on_macos_with_multipass/"},{"categories":["Systems"],"content":"The Focal Fossa nestles in on Santa Catalina Island Recently, I discovered that the Linux hypervisor, QEMU, is available on macOS. This is particularly exciting because I have to spin-up Linux VMs on macs at my day job, and I’ve wanted to get some more hands-on experience with QEMU. QEMU runs VMs quite efficiently and provides a robust set of tools for creating, managing, and running virtual machines. Additionally, it’s open-source and not controlled by Oracle. I also recommend checking out xhyve, a port of FreeBSDs hypervisor bhyve to macOS, and multipass, a cross-platform application for running Linux VMs. ","date":"2020-09-07","objectID":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/:0:0","tags":["Homebrew","Linux","macOS","MacPorts","QEMU","Ubuntu","Ubuntu2004","virtio","Virtualization"],"title":"Virtualize Ubuntu Desktop on macOS with QEMU","uri":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/"},{"categories":["Systems"],"content":"TutorialThis is a quick run-through on how to create and run a virtual Ubuntu 20.04 desktop machine on macOS Catalina using either QEMU 5.1 via Homebrew or QEMU 5.0 via MacPorts. This guide assumes you have familiarity with the command-line, virtual machines, ssh, port-forwarding, and graphical Linux installers. Install either Homebrew or MacPorts according to their installation instructions.Pull down the qemu package. # For Homebrew $ brew install qemu # For MacPorts $ sudo port install qemuCreate a 60 Gigabyte image to use as the VMs hard disk. $ qemu-img create -f qcow2 ubuntu2004.qcow2 60G Formatting 'ubuntu2004.qcow2', fmt=qcow2 size=64424509440 cluster_size=65536 lazy_refcounts=off refcount_bits=16Download the Ubuntu 20.04 desktop installer. $ curl -L -o ubuntu-20.04.1-desktop-amd64.iso https://releases.ubuntu.com/20.04/ubuntu-20.04.1-desktop-amd64.iso % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 2656M 100 2656M 0 0 8070k 0 0:05:37 0:05:37 --:--:-- 7717kVerify the ISO by following Canonical’s detailed tutorial.Boot the ISO installer $ qemu-system-x86_64 \\ -accel hvf \\ -cpu qemu64 \\ -smp 2 \\ -m 4G \\ -usb \\ -device usb-tablet \\ -vga virtio \\ -display default,show-cursor=on \\ -device virtio-net,netdev=vmnic -netdev user,id=vmnic \\ -audiodev coreaudio,id=coreaudio \\ -device ich9-intel-hda -device hda-output,audiodev=coreaudio \\ -cdrom ubuntu-20.04.1-desktop-amd64.iso \\ -drive file=ubuntu2004.qcow2,if=virtio That’s a long command-line, so I’ve broken it down option-by-option below. For more details, refer to the QEMU System Emulation User’s Guide. -accel hvfAccelerate the machine by taking advantage of the macOS hypervisor, hvf. kvm is available for Linux and whpx for Windows.-cpu qemu64Ideally, you would use the host option and get better performance by taking advantage of CPU passthrough.[1] However, this inevitably lead to a kernel panic when booting the ISO, unless the CPU was emulated. The default cpu option, qemu64, emulates the CPU instead of using passthrough.-smp 2Allocate two threads for the VM.-m 4GAllocate 4 GB of RAM for the VM.-usbEnable a USB bus.-device usb-tabletAvoid having to grab the mouse, making it easier to switch between interacting with the VM and the host.-vga virtioUse the virtio display card.-display default,show-cursor=onDon’t hide the cursor.-device virtio-net,netdev=vmnic -netdev user,id=vmnicPass-through networking with virtio.[2]-audiodev coreaudio,id=coreaudioAdd a backend audio driver for Apple’s Core Audio.-device ich9-intel-hda -device hda-output,audiodev=coreaudioAdd an audio bus and an output device utilizing the coreaudio driver created previously. This enables audio output from the guest.-cdrom ubuntu-20.04.1-desktop-amd64.isoAttach the Boot ISO in the VM as a CD.-drive file=ubuntu2004.qcow2,if=virtioAttach the hard-disk created earlier, using virtio drivers. The virtio options effectively pass-through directly to the hardware instead of emulating physical devices. Skipping this layer of emulation can significantly improve VM performance. Complete the installation in the virtual machine window which should appear after starting the VM.After the installation, run the virtual machine from the hard disk. $ qemu-system-x86_64 \\ -accel hvf \\ -cpu qemu64 \\ -smp 2 \\ -m 4G \\ -device usb-tablet \\ -vga virtio \\ -display default,show-cursor=on \\ -usb \\ -device virtio-net,netdev=vmnic -netdev user,id=vmnic \\ -audiodev coreaudio,id=coreaudio \\ -device ich9-intel-hda -device hda-output,audiodev=coreaudio \\ -drive file=ubuntu2004.qcow2,if=virtio ","date":"2020-09-07","objectID":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/:1:0","tags":["Homebrew","Linux","macOS","MacPorts","QEMU","Ubuntu","Ubuntu2004","virtio","Virtualization"],"title":"Virtualize Ubuntu Desktop on macOS with QEMU","uri":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/"},{"categories":["Systems"],"content":"SSHIt’s a small step away to run the virtual machine headless and access it through ssh. Run the virtual machine headless, forwarding ssh over port 9001 on the host. $ qemu-system-x86_64 \\ -accel hvf \\ -cpu qemu64 \\ -smp 2 \\ -m 4G \\ -device usb-tablet \\ -usb \\ -nographic \\ -device virtio-net,netdev=vmnic \\ -netdev user,id=vmnic,hostfwd=tcp:127.0.0.1:9001-:22 \\ -drive file=ubuntu2004.qcow2,if=virtioEnable SSH in the guest OS.ssh into the machine from the host. $ ssh -p 9001 localhost ","date":"2020-09-07","objectID":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/:1:1","tags":["Homebrew","Linux","macOS","MacPorts","QEMU","Ubuntu","Ubuntu2004","virtio","Virtualization"],"title":"Virtualize Ubuntu Desktop on macOS with QEMU","uri":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/"},{"categories":["Systems"],"content":"ConclusionYou should now be able to easily build and run Linux desktop virtual machines with QEMU on macOS. QEMU System Emulation Users Guide: QEMU CPU Models ↩Gentoo Wiki: QEMU/Options - Networking Pass-through ↩ ","date":"2020-09-07","objectID":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/:2:0","tags":["Homebrew","Linux","macOS","MacPorts","QEMU","Ubuntu","Ubuntu2004","virtio","Virtualization"],"title":"Virtualize Ubuntu Desktop on macOS with QEMU","uri":"/posts/virtualize_ubuntu_desktop_on_macos_with_qemu/"},{"categories":["Systems"],"content":"As I big fan of GNOME, I really wanted a similar experience on the PinePhone. That’s why I opted for running Manjaro ARM's alpha for the PinePhone, which comes in a GNOME-like Phosh flavor. It’s been running from the SD card great so far, but I thought to update the internal U-Boot as I did on the Pinebook Pro. ","date":"2020-09-04","objectID":"/posts/update_uboot_pinephone/:0:0","tags":["ArchLinux","Linux","Manjaro","PinePhone","UBoot"],"title":"Update U-Boot on the PinePhone","uri":"/posts/update_uboot_pinephone/"},{"categories":["Systems"],"content":"TutorialThis tutorial provides instructions for updating the PinePhone’s bootloader from Manjaro running off of a microSD card. This tutorial presumes you are comfortable using the command-line on Linux and the default Terminal app. ","date":"2020-09-04","objectID":"/posts/update_uboot_pinephone/:1:0","tags":["ArchLinux","Linux","Manjaro","PinePhone","UBoot"],"title":"Update U-Boot on the PinePhone","uri":"/posts/update_uboot_pinephone/"},{"categories":["Systems"],"content":"StepsFirst, ensure the system is up-to-date. $ sudo pacman -Syuu :: Synchronizing package databases... core is up to date extra is up to date community is up to date :: Starting full system upgrade... there is nothing to doNext, determine which device is the onboard eMMC module. $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 275.7M 1 loop /var/lib/anbox/rootfs mmcblk0 179:0 0 238.5G 0 disk 1 ├─mmcblk0p1 179:1 0 213.6M 0 part /boot └─mmcblk0p2 179:2 0 238.3G 0 part / mmcblk2 179:32 0 14.7G 0 disk 2 ├─mmcblk2p1 179:33 0 1.9M 0 part ├─mmcblk2p2 179:34 0 1M 0 part ├─mmcblk2p3 179:35 0 8M 0 part ├─mmcblk2p4 179:36 0 64M 0 part ├─mmcblk2p5 179:37 0 64.3M 0 part ├─mmcblk2p6 179:38 0 63.9M 0 part ├─mmcblk2p7 179:39 0 63.9M 0 part ├─mmcblk2p8 179:40 0 2.4G 0 part ├─mmcblk2p9 179:41 0 2.4G 0 part └─mmcblk2p10 179:42 0 8.6G 0 part mmcblk2boot0 179:64 0 4M 1 disk mmcblk2boot1 179:96 0 4M 1 diskmmcblk0 is the 250 GB SD card running Manjaro.mmcblk2 is the internal 16 GB eMMC module. Caution: Flashing to the wrong device could destroy your data. Flash the bin file to the eMMC.[1] $ sudo dd if=/boot/u-boot-sunxi-with-spl-pinephone.bin of=/dev/mmcblk2 bs=8k seek=1 88+1 records in 88+1 records out 725712 bytes (726 kB, 709 KiB) copied, 0.0612089 s, 11.9 MB/s ","date":"2020-09-04","objectID":"/posts/update_uboot_pinephone/:1:1","tags":["ArchLinux","Linux","Manjaro","PinePhone","UBoot"],"title":"Update U-Boot on the PinePhone","uri":"/posts/update_uboot_pinephone/"},{"categories":["Systems"],"content":"ConclusionThat’s all. You should now have the latest U-Boot booting your PinePhone! Manjaro ARM Gitlab: uboot-pinephone-crust ↩ ","date":"2020-09-04","objectID":"/posts/update_uboot_pinephone/:1:2","tags":["ArchLinux","Linux","Manjaro","PinePhone","UBoot"],"title":"Update U-Boot on the PinePhone","uri":"/posts/update_uboot_pinephone/"},{"categories":["Systems"],"content":"The other day, Elementary announced elementaryOS 6 preview builds for the Pinebook Pro. I went ahead and flashed an SD card with a build image to try it out. Instead of booting to elmentaryOS on the SD card as the system should have, it booted to Manjaro. While a quick restart from Manjaro caused the system to boot from the SD card, I figured it must be time to upgrade the bootloader, U-Boot. As it turns out, it was time because this solved my boot issue. ","date":"2020-08-23","objectID":"/posts/update_uboot_pinebook_pro/:0:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","UBoot"],"title":"Update U-Boot on the Pinebook Pro","uri":"/posts/update_uboot_pinebook_pro/"},{"categories":["Systems"],"content":"TutorialThis tutorial provides instructions for updating the Pinebook Pro’s bootloader from Manjaro Linux. ","date":"2020-08-23","objectID":"/posts/update_uboot_pinebook_pro/:1:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","UBoot"],"title":"Update U-Boot on the Pinebook Pro","uri":"/posts/update_uboot_pinebook_pro/"},{"categories":["Systems"],"content":"StepsFirst, ensure the system is up-to-date. $ sudo pacman -Syuu :: Synchronizing package databases... core is up to date extra is up to date community is up to date :: Starting full system upgrade... there is nothing to doNext, determine which device is the onboard eMMC module. $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 85.5M 1 loop /var/lib/snapd/snap/core/9806 loop1 7:1 0 85.8M 1 loop /var/lib/snapd/snap/core/9670 loop2 7:2 0 174.6M 1 loop /var/lib/snapd/snap/multipass/2446 loop3 7:3 0 62.2M 1 loop /var/lib/snapd/snap/snapcraft/5312 loop4 7:4 0 48.4M 1 loop /var/lib/snapd/snap/core18/1883 loop5 7:5 0 36.9M 1 loop /var/lib/snapd/snap/review-tools/1723 loop6 7:6 0 62.2M 1 loop /var/lib/snapd/snap/snapcraft/5282 loop7 7:7 0 48.8M 1 loop /var/lib/snapd/snap/core18/1888 loop8 7:8 0 173.6M 1 loop /var/lib/snapd/snap/multipass/2379 mmcblk2 179:0 0 58.2G 0 disk 1 ├─mmcblk2p1 179:1 0 213.6M 0 part /boot └─mmcblk2p2 179:2 0 58G 0 part / mmcblk2boot0 179:32 0 4M 1 disk mmcblk2boot1 179:64 0 4M 1 disk mmcblk1 179:96 0 238.5G 0 disk 2 zram0 252:0 0 5.6G 0 disk [SWAP]In this case, mmcblk2 is the internal 64 GB eMMC module.mmcblk1 happens to be a connected 250 GB SD card. Caution: Flashing to the wrong device could destroy your data. If you have an SD card connected, you might want to unplug it to be safe. Flash idbloader.img to the eMMC.[1] $ sudo dd if=/boot/idbloader.img of=/dev/mmcblk2 seek=64 conv=notrunc,fsync 322+1 records in 322+1 records out 164958 bytes (165 kB, 161 KiB) copied, 0.00663394 s, 24.9 MB/sFlash u-boot.itb to the eMMC. $ sudo dd if=/boot/u-boot.itb of=/dev/mmcblk2 seek=16384 conv=notrunc,fsync 1801+1 records in 1801+1 records out 922192 bytes (922 kb, 901 KiB) copied, 0.0833926 s, 11.1 MB/s ","date":"2020-08-23","objectID":"/posts/update_uboot_pinebook_pro/:1:1","tags":["ArchLinux","Linux","Manjaro","PinebookPro","UBoot"],"title":"Update U-Boot on the Pinebook Pro","uri":"/posts/update_uboot_pinebook_pro/"},{"categories":["Systems"],"content":"ConclusionThat’s all. You should now have the latest U-Boot booting your system! Manjaro ARM Gitlab: uboot-pinebookpro ↩ ","date":"2020-08-23","objectID":"/posts/update_uboot_pinebook_pro/:1:2","tags":["ArchLinux","Linux","Manjaro","PinebookPro","UBoot"],"title":"Update U-Boot on the Pinebook Pro","uri":"/posts/update_uboot_pinebook_pro/"},{"categories":null,"content":"Notice an error? Have a question? Find something helpful? Your feedback is welcome. Please feel free to contact me via email at jordan@jwillikers.com. You are also welcome to open an issue on this website’s Github repository. ","date":"2020-07-11","objectID":"/contact/:0:0","tags":null,"title":"Contact","uri":"/contact/"},{"categories":null,"content":"Welcome to jwillikers.com, where I like to put all of my handy admin and dev guides from my myriad of tinkering. My posts serve as convenient references for myself, but my hope is that they will help you as well. ","date":"2020-07-08","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"MeThis is my personal developer blog, so I’m taking the opportunity to talk a bit about myself. ","date":"2020-07-08","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"CareerThe reasons I pursue a career in software, engineering have continued to grow and evolve over time. Suffice it to say that I enjoy participating as part of a team to solve real and interesting problems in order to positively impact the lives of others. As a software engineer, I strive to write the least amount of simple and safe code required to complete a given task. Ideally, this amounts to writing no code at all because I’m able to discover that a perfectly adequate and tenable solution already exists. In the sections which follow I describe my experience in the field. Cross-platform Application DevelopmentAt my current day job, I wrangle C++ and CMake code to create functional, cross-platform graphical applications. Developing at a small company, my hands are in just about everything from project management to cross-platform application development to systems administration to licensing compliance. My focus here has been to learn how to write good C++ code, to improve the build system, and to implement both standard software engineering practices and agile development models. It has been challenging to implement better practices and processes while both maintaining a large, legacy code-base lacking any standards what-so-ever and adding high-quality code for new features. This is has been a phenomenal learning opportunity, but mostly in a trial-by-fire sort of way. Such circumstances have bred in me a deep appreciation of the software engineering principles which foster the production of maintainable code. This endeavor has also lead me to understand how the process of writing good code is impacted by management, project planning, collaboration, communication, and even company culture. Software Engineering InternPreviously, I interned at a cyber security company which developed log-analyzing security software. This was my first real introduction to software engineering, where I had the privilege to be a part of the backend developer team. This is where I learned first-hand how the fundamental software engineering practices such as version control, testing, code-reviews, continuous integration, and deployment all fit together. My work their included Java, Python, and Awk development as well as work on the Gradle build-system and integrating deployment to Docker. I even underwent certification as a Scrum master. Data AnalystBefore that, I interned as a data analyst at a healthcare institution. This lead to lots of SQL development and digging through backend databases. I became proficient at writing complex SQL queries, but most importantly, I was forced to think critically. I constantly had to question, \"Where is this data coming from?\" and, \"What does this really mean?\" at all times. ","date":"2020-07-08","objectID":"/about/:1:1","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"EducationI graduated with a bachelor’s degree in Computer Science with a concentration in Information Insurance. Although I prefer the applied, a degree in the more theoretical aspects of Computer Science was quite rewarding, stretching me to understand the underpinning aspects of computing. The experience in cyber security brought with it a cautious and proactive mindset, which influences how I think about and write code today. ","date":"2020-07-08","objectID":"/about/:1:2","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Development PreferencesI like writing code to make people’s lives easier. Unfortunately, I’ve learned from experience that poor code has a tendency to make the lives of everyone more difficult, especially for developers. This has ingrained in me strong convictions for utilizing standard software engineering practices, high-quality open source software, and the best tooling available to create safe and maintainable code. There is also nothing like having fun and learning new things while solving a challenging problem. This is why languages which pursue safety and simplicity, such as Rust and Go, are my favorites. They tend allow me to focus on the problem at hand rather than frustrate me with issues and complexities inherent in the language. ","date":"2020-07-08","objectID":"/about/:1:3","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"InterestsIf you haven’t figured it out yet, I’m big proponent of open-source software where high-quality solutions to common problems abound. I enjoy collaborating with other developers to improve open-source software for everyone. Desktop Linux, namely Ubuntu and GNOMEOpen-hardware mobile devices (and relevant software), such as the Pinebook Pro, PinePhone, and PineTab developed by Pine64Safe, simple, and easy-to-use programming languages like Rust and GoOpenBSDFreeBSDOpenZFSRISC-V ","date":"2020-07-08","objectID":"/about/:1:4","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"HobbiesAs for hobbies outside of tech, I enjoy spending time with my wife, yoga, cooking, socializing, listening to podcasts and books, hiking, and generally getting outside whenever possible. ","date":"2020-07-08","objectID":"/about/:1:5","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"There’s always so much to learn in any industry. As a full time Software Engineer, there is more out there for me to learn than neurons in between my ears. Putting networking and systems administration on top of that is downright overwhelming. Fortunately, I’ve found several priceless resources to help me learn. ","date":"2020-07-06","objectID":"/resources/:0:0","tags":null,"title":"Resources","uri":"/resources/"},{"categories":null,"content":"Software EngineeringSoftware Engineering at Google - If I had to be stranded on a deserted island with other Software Engineers and could only bring one item, I would bring this book without thinking twice. ","date":"2020-07-06","objectID":"/resources/:1:0","tags":null,"title":"Resources","uri":"/resources/"},{"categories":null,"content":"ProgrammingConcurrency in Action - The best concurrency metaphors I’ve yet to come across.CppCast - This podcast has introduced me to an incredibly diverse range of people, projects, features, and tools related to C++.Professional CMake - This book is a life-saver when digging through CMake code.The Rust Programming Language ","date":"2020-07-06","objectID":"/resources/:2:0","tags":null,"title":"Resources","uri":"/resources/"},{"categories":null,"content":"Systems Administration / Networking2.5 AdminsJim Salter at Ars Technica ","date":"2020-07-06","objectID":"/resources/:3:0","tags":null,"title":"Resources","uri":"/resources/"},{"categories":null,"content":"*BSDAbsolute FreeBSDAbsolute OpenBSDBSDNow ","date":"2020-07-06","objectID":"/resources/:3:1","tags":null,"title":"Resources","uri":"/resources/"},{"categories":null,"content":"LinuxLinux UnpluggedUbuntu Podcast ","date":"2020-07-06","objectID":"/resources/:3:2","tags":null,"title":"Resources","uri":"/resources/"},{"categories":["Systems"],"content":"Note: This tutorial is out-of-date and will be updated when I get ZFS working again on the Pinebook Pro. The Pinebook Pro comes with a small amount of internal disk space, only 64 GB. While this is upgradeable to 128 GB, that still isn’t enough for those with large media collections. The easiest solution is to use a microSD card. And now you’re just dying to use ZFS on that, right? ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:0:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"TutorialFollowing the previous post, Install ZFS on the Pinebook Pro, this tutorial describes the steps required to setup a microSD card for your music files with ZFS on the Pinebook Pro. ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"Create the PoolThe microSD card will need to be provisioned as its own pool using ZFS. Adding the disk to a pool places it under the control of ZFS, providing all of the necessary ZFS capabilities. First, determine which device is the microSD card. $sudo fdisk -l Disk /dev/mmcblk2: 58.25 GiB, 62537072640 bytes, 122142720 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x33192aaf Device Boot Start End Sectors Size Id Type /dev/mmcblk2p1 62500 500000 437501 213.6M c W95 FAT32 (LBA) /dev/mmcblk2p2 500001 122142719 121642719 58G 83 Linux Disk /dev/mmcblk1: 238.51 GiB, 256087425024 bytes, 500170752 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x00000000 Device Boot Start End Sectors Size Id Type /dev/mmcblk1p1 65536 500170751 500105216 238.5G 7 HPFS/NTFS/exFAT ... In this case, /dev/mmcblk1 is the 256GB microSD card. Next, determine the disk id to use when creating the zpool.[1] $ls -lh /dev/disk/by-id/ | grep -w mmcblk1 lrwxrwxrwx 1 root root 13 Jun 24 07:33 mmc-AB5CD_0x00000001 -\u003e../../mmcblk1Then, check the block size. $sudo blockdev --getpbsz /dev/mmcblk1 512 The SD card’s block size is 512 MiB, which means ashift should be set to 12.[2] Create the pool.[3] $sudo zpool create \\ -o ashift=12 \\ -O compression=on \\ 1 ext_pool mmc-AB5CD_0x00000001Turn on compression by default. Configure the system to automatically import the pool on boot.[4] $sudo zpool set cachefile=/etc/zfs/zpool.cache ext_pool ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:1","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"Create the DatasetWith the microSD card now managed by ZFS, it is now possible to create the ZFS dataset for storing your music. Create the ZFS dataset for your tunes. $sudo zfs create \\ -o recordsize=1M \\ 1 -o mountpoint=/home/jordan/Music \\ ext_pool/musicA nifty trick here is to use a larger recordsize of 1 MiB which more accurately reflects the filesystem operations for large media files.[5] Set the appropriate ownership for the mounted ~/Music directory. $sudo chown -R jordan:jordan /home/jordan/Music ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:2","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"CopyNow, just copy the music files from wherever they happen to be to the dataset. The simplest way is to copy the files over the network. Since the pool is on an SD card, you might just want to pop it out and carry it between machines, so I describe that here. Export the pool from the Pinebook Pro. $sudo zpool export ext_poolPop-out the microSD card and pop it into the machine with all of the music.Import the pool. $sudo zpool import ext_pool cannot mount '/home/jordan/Music': directory is not emptyChange where the music dataset is mounted. I keep my music in ~/Music, so I have to mount the dataset somewhere else. $sudo zfs set mountpoint=/media/jordan/Music ext_pool/musicMount the dataset to the updated location. $sudo zfs mount ext_pool/musicSet the appropriate ownership for the mounted directory. $sudo chown jordan:jordan /media/jordan/MusicCopy over the music. $tar cfC - /home/jordan/Music . | tar xpfC - /media/jordan/MusicThen change the mount location back to ~/Music. $sudo zfs set mountpoint=/home/jordan/Music ext_pool/music cannot mount '/home/jordan/Music': directory is not empty property may be set but unable to remount filesystemExport the pool from the machine. $sudo zpool export ext_poolNow place the SD card back into the Pinebook Pro, and import the pool again. $sudo zpool import ext_pool ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:3","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"VerifyIf everything is successful, your music should now be available in ~/Music. You should also check that the pool and music dataset are automatically mounted at boot. $sudo reboot ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:4","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"EnjoyYou can now enjoy your vast music collection from the comfort of your Pinebook Pro. Arch Linux Wiki: Identify Disks ↩Arch Linux Wiki: ZFS - Advanced Format Disks ↩Arch Linux Wiki: ZFS - Creating ZFS Pools ↩Arch Linux Wiki: ZFS - Automatic Start ↩JRS Systems: About ZFS recordsize ↩ ","date":"2020-07-03","objectID":"/posts/zfs_external_storage_pinebook_pro/:1:5","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"External Storage on the Pinebook Pro with ZFS","uri":"/posts/zfs_external_storage_pinebook_pro/"},{"categories":["Systems"],"content":"Backups are super helpful, especially when you like to blow everything away fairly often. Backing up the data from a Docker container can help you quickly get things up and running again. ","date":"2020-07-02","objectID":"/posts/backup_docker_data/:0:0","tags":["Containers","Docker","Linux","Ubuntu","Ubuntu2004"],"title":"Backup Docker Data","uri":"/posts/backup_docker_data/"},{"categories":["Systems"],"content":"TutorialMy recent post detailed how to setup a UniFi Controller in a Docker container. This tutorial uses that container as an example for creating and restoring backups of data volumes. ","date":"2020-07-02","objectID":"/posts/backup_docker_data/:1:0","tags":["Containers","Docker","Linux","Ubuntu","Ubuntu2004"],"title":"Backup Docker Data","uri":"/posts/backup_docker_data/"},{"categories":["Systems"],"content":"BackupCreating backups is done by producing an archive of the important files on the host filesystem from the container’s data volume. $docker run \\ --rm \\ 1 --volumes-from unifi-controller \\ 2 -v $(pwd):/backup \\ 3 ubuntu tar cvWf /backup/unifi-controller_backup_$(date +%F).tar -C /config unifi-controller 4Remove the container when finished.Attach the data volumes for the container named unifi-controller.Mount the current directory to /backup in the container.Using an Ubuntu image, create an archive of the directory /config/unifi-controller in the /backup directory. Compress the backup. $xz unifi-controller_backup_2020-07-01.tar ","date":"2020-07-02","objectID":"/posts/backup_docker_data/:1:1","tags":["Containers","Docker","Linux","Ubuntu","Ubuntu2004"],"title":"Backup Docker Data","uri":"/posts/backup_docker_data/"},{"categories":["Systems"],"content":"RestoreTo restore from a backup, just reverse the backup process. Decompress the backup. $unxz unifi-controller_backup_2020-07-01.tar.xzRestore the contents of the archive to the data volume. $docker run --rm \\ 1 --volumes-from unifi-controller \\ 2 -v $(pwd):/backup \\ 3 ubuntu tar xvf /backup/unifi-controller_backup_2020-07-01.tar -C / 4 Remove the container when finished.Attach the data volumes for the container named unifi-controller.Mount the current directory to /backup in the container.Using an Ubuntu image, expand the archive in the / directory. ","date":"2020-07-02","objectID":"/posts/backup_docker_data/:1:2","tags":["Containers","Docker","Linux","Ubuntu","Ubuntu2004"],"title":"Backup Docker Data","uri":"/posts/backup_docker_data/"},{"categories":["Systems"],"content":"VerifyIt’s always important to test your backups. The simplest way to check the backup is with a fresh instance of the container. For the UniFi Controller, this is trivially accomplished. First, copy the compose file to another directory and give the container a new name. $mkdir unifi-controller2 $cp unifi-controller/docker-compose.yml unifi-controller2 $cd unifi-controller2Modify the yaml file to match the following. docker-compose.yml --- version: \"2.1\" services: unifi-controller: image: linuxserver/unifi-controller container_name: unifi-controller2 1 environment: - PUID=1000 - PGID=1000 - MEM_LIMIT=1024M #optional volumes: - data:/config ports: - 3478:3478/udp - 10001:10001/udp - 8080:8080 - 8081:8081 - 8443:8443 - 8843:8843 - 8880:8880 - 6789:6789 restart: unless-stopped volumes: data:Name the container unifi-controller2. Initialize the container. $docker-compose up --no-startDecompress the backup. $unxz unifi-controller_backup_2020-07-01.tar.xzRestore the contents of the archive to the new container’s data volume. $docker run --rm \\ --volumes-from unifi-controller2 \\ 1 -v $(pwd):/backup \\ ubuntu tar xvf /backup/unifi-controller_backup_2020-07-01.tar -C /Attach the data volumes for the new unifi-controller2 container. That’s it! The data from your original container should now be duplicated in unifi-controller2. Now, start unifi-controller2. $docker-compose up -dThen, open the UniFi Controller’s web UI. $xdg-open http://127.0.0.1:8443Login just as you would on the unifi-controller container and verify that your restored controller’s configuration matches the original. You have now learned how to back up and restore the data in a Docker container’s data volume. ","date":"2020-07-02","objectID":"/posts/backup_docker_data/:1:3","tags":["Containers","Docker","Linux","Ubuntu","Ubuntu2004"],"title":"Backup Docker Data","uri":"/posts/backup_docker_data/"},{"categories":["Systems"],"content":"Recently, I obtained a 64-bit ARM, budget Linux laptop, the Pinebook Pro. It’s a wonderful, sleek little notebook, boasting great convenience and power-efficiency. I enjoy using it so much, it’s becoming my main machine, and I’d love love to put all of my music, audiobooks, pictures, and ebooks on it. The only problem being my media takes up a bit more than the 64 GiB available on the machine’s built-in eMMC. With a spacious microSD card in-hand, I knew it was time to get more experience with my new filesystem of choice ZFS. ","date":"2020-06-30","objectID":"/posts/install_zfs_pinebook_pro/:0:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"Install ZFS on the Pinebook Pro","uri":"/posts/install_zfs_pinebook_pro/"},{"categories":["Systems"],"content":"TutorialThis tutorial describes the steps required to install ZFS on a Pinebook Pro running the tailored version of Manjaro KDE. ","date":"2020-06-30","objectID":"/posts/install_zfs_pinebook_pro/:1:0","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"Install ZFS on the Pinebook Pro","uri":"/posts/install_zfs_pinebook_pro/"},{"categories":["Systems"],"content":"InstallThe ZFS software is readily available as a DKMS module for the arm64 architecture. The following instructions detail how to install the ZFS DKMS module. First, install DKMS on the Pinebook Pro.[1] $ sudo pacman -S dkms linux-pinebookpro-headersThe yay tool provides a nifty way to install packages from the AUR. $ sudo pacman -S yayThen, install the zfs-dkms-any package from the AUR. $ yay -S zfs-dkms-any ","date":"2020-06-30","objectID":"/posts/install_zfs_pinebook_pro/:1:1","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"Install ZFS on the Pinebook Pro","uri":"/posts/install_zfs_pinebook_pro/"},{"categories":["Systems"],"content":"ConfigureIt’s likely you want to have ZFS available without having to explicitly load the DKMS module, import pools, and mount datasets every time you restart your computer. These next steps describe exactly how to avoid such nonsense. To load the ZFS DKMS module at boot, create the appropriate file for systemd.[2] /etc/modules-load.d/zfs.conf # Load ZFS at boot zfsEnable importing pools and mounting datasets at boot.[3] $ sudo systemctl enable zfs-import-cache $ sudo systemctl enable zfs-import.target $ sudo systemctl enable zfs-mount $ sudo systemctl enable zfs.target ","date":"2020-06-30","objectID":"/posts/install_zfs_pinebook_pro/:1:2","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"Install ZFS on the Pinebook Pro","uri":"/posts/install_zfs_pinebook_pro/"},{"categories":["Systems"],"content":"Next StepsSee External Storage on the Pinebook Pro with ZFS to learn how to use ZFS to store your files on a microSD card. Arch Linux Wiki: Dynamic Kernel Module Support ↩Arch Linux Wiki: Kernel Module - Automatic Module Loading with systemd ↩Arch Linux Wiki: ZFS - Automatic Start ↩ ","date":"2020-06-30","objectID":"/posts/install_zfs_pinebook_pro/:1:3","tags":["ArchLinux","Linux","Manjaro","PinebookPro","ZFS"],"title":"Install ZFS on the Pinebook Pro","uri":"/posts/install_zfs_pinebook_pro/"},{"categories":["Networking"],"content":"For wi-fi, I use use a UniFi AP. One slightly annoying aspect of this is the UniFi Controller. If you don’t have a smartphone or need to manage more than one device, you’ll need to set one up. I provide a brief tutorial for setting up the UniFi Controller with Docker Compose here. ","date":"2020-05-30","objectID":"/posts/unifi_controller/:0:0","tags":["Containers","Docker","DockerCompose","Linux","UniFi","UniFiController","Ubuntu","Ubuntu2004"],"title":"UniFi Controller","uri":"/posts/unifi_controller/"},{"categories":["Networking"],"content":"TutorialAn existing Docker image makes setting up the UniFi Controller a breeze. Here’s how. ","date":"2020-05-30","objectID":"/posts/unifi_controller/:1:0","tags":["Containers","Docker","DockerCompose","Linux","UniFi","UniFiController","Ubuntu","Ubuntu2004"],"title":"UniFi Controller","uri":"/posts/unifi_controller/"},{"categories":["Networking"],"content":"Install DockerFirst, you must install Docker on your system. Install Docker Compose. $sudo apt install docker-composeAdd your user to the docker group if you want to run docker without requiring superuser privileges. $sudo usermod -aG docker $USERReboot to complete the installation. $sudo reboot ","date":"2020-05-30","objectID":"/posts/unifi_controller/:1:1","tags":["Containers","Docker","DockerCompose","Linux","UniFi","UniFiController","Ubuntu","Ubuntu2004"],"title":"UniFi Controller","uri":"/posts/unifi_controller/"},{"categories":["Networking"],"content":"ComposeConfiguring the docker-compose file should provide all of the necessary details required to get the controller up and running. With Docker installed, create a directory for the docker-compose file. $mkdir unifi_controller $cd unifi_controllerConfigure the docker-compose file. The provided docker-compose file requires just one tweak, configuring the volume. docker-compose.yml --- version: \"2.1\" services: unifi-controller: image: linuxserver/unifi-controller container_name: unifi-controller environment: - PUID=1000 - PGID=1000 - MEM_LIMIT=1024M #optional volumes: - data:/config ports: - 3478:3478/udp - 10001:10001/udp - 8080:8080 - 8081:8081 - 8443:8443 - 8843:8843 - 8880:8880 - 6789:6789 restart: unless-stopped volumes: data: The docker-compose should be pretty self-explanatory. It really just forwards the necessary ports from the Docker container to the host machine. Once configured, run the container. $docker-compose up -dThen, just open the UniFi Controller’s web UI. $xdg-open http://127.0.0.1:8443 ","date":"2020-05-30","objectID":"/posts/unifi_controller/:1:2","tags":["Containers","Docker","DockerCompose","Linux","UniFi","UniFiController","Ubuntu","Ubuntu2004"],"title":"UniFi Controller","uri":"/posts/unifi_controller/"},{"categories":["Networking"],"content":"Recently, Firefox announced it’s roll-out of DNS over HTTPS (DoH). That made me think, \"Encrypting DNS…​ Why don’t I do that for my home network?\" Well, I’ve now had the opportunity to configure my Unbound DNS resolver to encrypt it’s DNS requests. Unbound has support built-in for DoH’s sibling protocol, DNS over TLS (DoT). Instead of encrypting DNS traffic and masking it as standard HTTPS traffic, it uses the dedicated port 853. ","date":"2020-05-29","objectID":"/posts/unbound_dns_over_tls/:0:0","tags":["BSD","DNS","DoT","OpenBSD","OpenBSD6","OpenBSD67","TLS","Unbound"],"title":"DNS over TLS with Unbound","uri":"/posts/unbound_dns_over_tls/"},{"categories":["Networking"],"content":"TutorialThis tutorial describes the steps required to setup DNS over TLS on Unbound 1.10.1 on an OpenBSD 6.7 system. ","date":"2020-05-29","objectID":"/posts/unbound_dns_over_tls/:1:0","tags":["BSD","DNS","DoT","OpenBSD","OpenBSD6","OpenBSD67","TLS","Unbound"],"title":"DNS over TLS with Unbound","uri":"/posts/unbound_dns_over_tls/"},{"categories":["Networking"],"content":"ConfigureConfiguration is done in the unbound.conf file. The vanilla unbound.conf requires little more than un-commenting a few lines. Set tls-cert-bundle to the location of the system’s certificates, which is /etc/ssl/cert.pem on OpenBSD 6.7. /var/unbound/etc/unbound.conf # CA Certificates used for forward-tls-upstream (RFC7858) hostname # verification. Since it's outside the chroot it is only loaded at # startup and thus cannot be changed via a reload. tls-cert-bundle: \"/etc/ssl/cert.pem\" Un-comment the DNS-over-TLS forward-zone section, and add your desired DNS entries. /var/unbound/etc/unbound.conf # Use an upstream DNS-over-TLS forwarder and do not fall back to cleartext # if that fails. forward-zone: name: \".\" forward-tls-upstream: yes # use DNS-over-TLS forwarder forward-first: no # do NOT send direct # # the hostname after \"#\" is not a comment, it is used for TLS checks: forward-addr: 2606:4700:4700::1111@853#cloudflare-dns.com forward-addr: 1.1.1.1@853#cloudflare-dns.com forward-addr: 2606:4700:4700::1001@853#cloudflare-dns.com forward-addr: 1.0.0.1@853#cloudflare-dns.com Note: This configuration uses Cloudflare’s DNS servers. Make sure that whichever servers you choose support DNS over TLS. That is all it takes to configure DNS over TLS. But before moving on, take a moment to admire those lovely comments from the package maintainers. You don’t see comments that make a task so easy all that often. To be on the safe side, verify the configuration of unbound.conf with unbound-checkconf. $unbound-checkconf unbound-checkconf: no errors in /var/unbound/etc/unbound.conf Did you read those comments? Restart the machine for the changes to take effect. $reboot ","date":"2020-05-29","objectID":"/posts/unbound_dns_over_tls/:1:1","tags":["BSD","DNS","DoT","OpenBSD","OpenBSD6","OpenBSD67","TLS","Unbound"],"title":"DNS over TLS with Unbound","uri":"/posts/unbound_dns_over_tls/"},{"categories":["Networking"],"content":"VerifyCould the configuration really be that easy? It’s probably best to check if DNS requests are truly being encrypted. A packet capture can show that. Start capturing all DNS traffic from the Unbound server to the upstream DNS. $tcpdump -v -i em0 -s 65535 -w dns.pcap dst port 53 or 853 1Capture packets on the egress interface, em0. Capture all traffic going to the standard DNS and DoT ports, port 53 and 853 respectively. Write the capture to the file dns.pcap Then do some digging or web browsing from a host using the Unbound resolver. $dig mozilla.org Use Ctrl-C to end the packet capture. Next, analyze the packet capture. I opened up the packet capture in Wireshark on my laptop. But, it’s just as easy to view it on the terminal with tshark. Optionally, install tshark. $pkg_add wireshark --no_x11 Review DNS requests in the packet capture. Here I use tshark. $tshark -r dns.pcap 1 0.000000 2001:DB8::1 ? 2606:4700:4700::1001 TCP 98 38416 ? 853 [SYN] Seq=0 Win=16384 Len=0 MSS=1440 SACK_PERM=1 WS=64 TSval=3906316800 TSecr=0 2 0.000105 2001:DB8::1 ? 2606:4700:4700::1001 TCP 98 16888 ? 853 [SYN] Seq=0 Win=16384 Len=0 MSS=1440 SACK_PERM=1 WS=64 TSval=1343386395 TSecr=0 3 0.005709 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 38416 ? 853 [ACK] Seq=1 Ack=1 Win=16384 Len=0 4 0.005710 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 16888 ? 853 [ACK] Seq=1 Ack=1 Win=16384 Len=0 5 0.006150 2001:DB8::1 ? 2606:4700:4700::1001 TLSv1 386 Client Hello 6 0.006494 2001:DB8::1 ? 2606:4700:4700::1001 TLSv1 386 Client Hello 7 0.012466 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 38416 ? 853 [ACK] Seq=313 Ack=2721 Win=13632 Len=0 8 0.012468 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 16888 ? 853 [ACK] Seq=313 Ack=2721 Win=13632 Len=0 9 0.013037 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 38416 ? 853 [ACK] Seq=313 Ack=2742 Win=16384 Len=0 10 0.019366 2001:DB8::1 ? 2606:4700:4700::1001 TLSv1.2 148 Application Data 11 0.019892 2001:DB8::1 ? 2606:4700:4700::1001 TCP 74 16888 ? 853 [ACK] Seq=313 Ack=2741 Win=16384 Len=0 You should see output similar to that above. A TLSv1.2 connection is established between the Unbound server and Cloudflare’s DNS server 2606:4700:4700::1001. In this packet capture, un-encrypted DNS traffic over port 53 is entirely absent. That means all DNS requests from the router to the DNS server are encrypted! ","date":"2020-05-29","objectID":"/posts/unbound_dns_over_tls/:1:2","tags":["BSD","DNS","DoT","OpenBSD","OpenBSD6","OpenBSD67","TLS","Unbound"],"title":"DNS over TLS with Unbound","uri":"/posts/unbound_dns_over_tls/"},{"categories":["Systems"],"content":"I recently fixed my mother-in-law’s laptop. Long story short, the hard disk was toast. When I repaired the computer, I decided it would be best to avoid the frustration and confusion of a failing hard drive in the future. So, how does one know if his or her mother-in-law’s hard disk is reaching senility? SmartMonTools appears to be the best tool for the job. It’s a tool for monitoring and reporting hard disk health with Self-Monitoring, Anlysis, and Reporting Technology (SMART) which is built into most hard drives. SmartMonTools is even cross-platform and available in package repositories everywhere. ","date":"2020-05-25","objectID":"/posts/smartd_ubuntu/:0:0","tags":["Email","Linux","OpenSMTPD","SMART","smartd","SmartMonTools","SMTP","Ubuntu","Ubuntu2004"],"title":"Automatically Detect \u0026 Report Hard Drive Failure","uri":"/posts/smartd_ubuntu/"},{"categories":["Systems"],"content":"TutorialThis tutorial describes the steps required to setup automated hard disk health checks and email notifications using SmartMonTools 7.1 on Ubuntu 20.04. If you’re configuring a desktop like me or otherwise configuring a system which doesn’t have a MTA (Mail Transport Agent) or MUA (Mail User Agent) setup already and wish to send emails externally, I recommend following my tutorial on setting up an OpenSMTPD Relay on Ubuntu. Emails sent straight from a willy-nilly desktop user account to an online email provider are unlikely to be accepted. With SMTP, your system can relay emails through your online email provider to remedy this. ","date":"2020-05-25","objectID":"/posts/smartd_ubuntu/:1:0","tags":["Email","Linux","OpenSMTPD","SMART","smartd","SmartMonTools","SMTP","Ubuntu","Ubuntu2004"],"title":"Automatically Detect \u0026 Report Hard Drive Failure","uri":"/posts/smartd_ubuntu/"},{"categories":["Systems"],"content":"InstallFirst, install SmartMonTools on Ubuntu. $apt install smartmontools ","date":"2020-05-25","objectID":"/posts/smartd_ubuntu/:1:1","tags":["Email","Linux","OpenSMTPD","SMART","smartd","SmartMonTools","SMTP","Ubuntu","Ubuntu2004"],"title":"Automatically Detect \u0026 Report Hard Drive Failure","uri":"/posts/smartd_ubuntu/"},{"categories":["Systems"],"content":"ConfigureThe tool to monitor your system is, of course, smartd. Configuration is done in /etc/smartd.conf. Consult the smartd.conf manpage for more details. The smartd.conf below provides a complete configuration example. It checks the SATA disk /dev/sda for various types of failures, schedules regular self-tests, reports any errors via email, and avoids consuming excessive energy by frequently waking the disk. /etc/smartd.conf /dev/sda \\ 1 -d sat \\ 2 -o on \\ 3 -S on \\ 4 -H \\ 5 -l error \\ 6 -l selftest \\ 7 -f \\ 8 -n standby,15,q \\ 9 -s (L/../(01|16)/./03|S/../.././01|O/../.././(00|06|12|18)) \\ 10 -m jdoe@gmail.com \\ 11 -M exec /usr/share/smartmontools/smartd-runner 12Run for the device /dev/sda.Specify that the device uses a SCSI to ATA Translation interface.Enable SMART Automatic Offline Testing.Automatically save SMART attributes.Check the health status of the disk for failing health status.Report if there are any new SMART errors.Report if there are any new SMART errors for any self-tests.Check for failure of any Usage Attributes.Check the device unless it is in SLEEP or STANDBY mode. Wake it up after 15 skipped checks. Don’t log the skipped test, which could wake-up the disk.Schedule long self-tests for the first and sixteenth days of the month at 3 AM, short self-tests daily at 1 AM, and Offline Immediate Tests four times each day at midnight, 6 AM, noon, and 6 PM.Email jdoe@gmail.com if any errors are detected.Execute /usr/share/smartmontools/smartd-runner instead of the default mail command when sending emails. Enable smartd on system startup. $systemctl enable smartd ","date":"2020-05-25","objectID":"/posts/smartd_ubuntu/:1:2","tags":["Email","Linux","OpenSMTPD","SMART","smartd","SmartMonTools","SMTP","Ubuntu","Ubuntu2004"],"title":"Automatically Detect \u0026 Report Hard Drive Failure","uri":"/posts/smartd_ubuntu/"},{"categories":["Systems"],"content":"VerifyYou will probably want to double check the scheduling and emailing behavior, at the very least. SchedulingAudit the self-test schedule with smartd -q showtests. This will show the next five tests scheduled for each type of self-test. It also shows the total number of tests for each type of self-test for the next ninety days. $smartd -q showtests smartd 7.1 2019-12-30 r5022 [x86_64-linux-5.4.0-31-generic] (local build) Copyright (C) 2002-19, Bruce Allen, Christian Franke, www.smartmontools.org Opened configuration file /etc/smartd.conf Configuration file /etc/smartd.conf parsed. Device: /dev/sda, opened Device: /dev/sda, CT2000MX500SSD1, S/N:000000000001, WWN:0-000000-000000000, FW:M3CR023, 2.00 TB Device: /dev/sda, found in smartd database: Crucial/Micron MX500 SSDs Device: /dev/sda, WARNING: This firmware returns bogus raw values in attribute 197 Device: /dev/sda, enabled SMART Attribute Autosave. Device: /dev/sda, enabled SMART Automatic Offline Testing. Device: /dev/sda, is SMART capable. Adding to \"monitor\" list. Device: /dev/sda, state read from /var/lib/smartmontools/smartd.CT2000MX500SSD1-000000000001.ata.state Monitoring 1 ATA/SATA, 0 SCSI/SAS and 0 NVMe devices Next scheduled self tests (at most 5 of each type per device): Device: /dev/sda, will do test 1 of type O at Mon May 25 12:25:20 2020 CDT Device: /dev/sda, will do test 2 of type O at Mon May 25 18:25:20 2020 CDT Device: /dev/sda, will do test 3 of type O at Tue May 26 00:25:20 2020 CDT Device: /dev/sda, will do test 1 of type S at Tue May 26 01:25:20 2020 CDT Device: /dev/sda, will do test 4 of type O at Tue May 26 06:25:20 2020 CDT Device: /dev/sda, will do test 5 of type O at Tue May 26 12:25:20 2020 CDT Device: /dev/sda, will do test 2 of type S at Wed May 27 01:25:20 2020 CDT Device: /dev/sda, will do test 3 of type S at Thu May 28 01:25:20 2020 CDT Device: /dev/sda, will do test 4 of type S at Fri May 29 01:25:20 2020 CDT Device: /dev/sda, will do test 5 of type S at Sat May 30 01:25:20 2020 CDT Device: /dev/sda, will do test 1 of type L at Mon Jun 1 03:25:20 2020 CDT Device: /dev/sda, will do test 2 of type L at Tue Jun 16 03:25:20 2020 CDT Device: /dev/sda, will do test 3 of type L at Wed Jul 1 03:25:20 2020 CDT Device: /dev/sda, will do test 4 of type L at Thu Jul 16 03:25:20 2020 CDT Device: /dev/sda, will do test 5 of type L at Sat Aug 1 03:25:20 2020 CDT Totals [Mon May 25 10:25:20 2020 CDT - Sun Aug 23 10:25:20 2020 CDT]: Device: /dev/sda, will do 6 tests of type L Device: /dev/sda, will do 90 tests of type S Device: /dev/sda, will do 0 tests of type C Device: /dev/sda, will do 360 tests of type O Further verification can be done to make sure self-tests are running at the scheduled times. After an amount of time where smartd is expected to run some self-tests, check the self-test log with smartctl. The log shows that one short offline test has been run without error. $smartctl -d sat -l xselftest,25,selftest /dev/sda smartctl 7.1 2019-12-30 r5022 [x86_64-linux-5.4.0-31-generic] (local build) Copyright (C) 2002-19, Bruce Allen, Christian Franke, www.smartmontools.org === START OF READ SMART DATA SECTION === SMART Extended Self-test Log Version: 1 (1 sectors) Num Test_Description Status Remaining LifeTime(hours) LBA_of_first_error #1 Short offline Completed without error 00% 460 - Email AlertsTo test the email functionality, you can tell smartd to send a test email. /etc/smartd.conf /dev/sda \\ -d sat \\ -o on \\ -S on \\ -H \\ -l error \\ -l selftest \\ -f \\ -n standby,15,q \\ -s (L/../(01|16)/./03|S/../.././01|O/../.././(00|06|12|18)) \\ -m jdoe@gmail.com \\ -M test \\ 1 -M exec /usr/share/smartmontools/smartd-runnerSend a test email when smartd starts. Restart smartd so that it sends the test email. $systemctl restart smartd If everything works, you should receive an email at the designated address. Caution: Make sure to remove the -M test directive from the file so you don’t spam yourself. ","date":"2020-05-25","objectID":"/posts/smartd_ubuntu/:1:3","tags":["Email","Linux","OpenSMTPD","SMART","smartd","SmartMonTools","SMTP","Ubuntu","Ubuntu2004"],"title":"Automatically Detect \u0026 Report Hard Drive Failure","uri":"/posts/smartd_ubuntu/"},{"categories":["Networking"],"content":"It can be handy to have your system email you if it detects an issue or potential security risk. Unfortunately, this isn’t always straightforward, especially when you want to send an email from your desktop computer. Sending an email directly from your desktop to your email account is likely going to accomplish nothing. The email will likely be blocked since, to your email provider, it is from an unknown source. I ran into this problem recently trying to set up SmartMonTools to send an email when it detected hard drive errors. The Simple Mail Transfer Protocal (SMTP) is perfect for getting around this by relaying the email through your account from an established email provider. In my instance, I wanted to relay the alert through my GMail account, which has nice support for SMTP. Using an Ubuntu desktop computer, I figured this would be a breeze. It wasn’t. It turned out to be much harder than I anticipated because many guides demonstrate SMTP relay using antiquated applications, such as SSMTP. Being an OpenBSD fanboy, I with the modern OpenSMTPD application. ","date":"2020-05-24","objectID":"/posts/opensmtpd_ubuntu/:0:0","tags":["2FA","Email","GMail","Linux","OpenSMTPD","OpenSMTPD6","SMTP","Ubuntu","Ubuntu2004"],"title":"OpenSMTPD Relay on Ubuntu","uri":"/posts/opensmtpd_ubuntu/"},{"categories":["Networking"],"content":"InstructionsThis brief guide will walk you through relaying emails on Ubuntu 20.04 with OpenSMTPD 6.6.4. ","date":"2020-05-24","objectID":"/posts/opensmtpd_ubuntu/:1:0","tags":["2FA","Email","GMail","Linux","OpenSMTPD","OpenSMTPD6","SMTP","Ubuntu","Ubuntu2004"],"title":"OpenSMTPD Relay on Ubuntu","uri":"/posts/opensmtpd_ubuntu/"},{"categories":["Networking"],"content":"InstallFirst, install OpenSMTPD on Ubuntu. $apt install opensmtpd Note: This will probably ask you a couple of questions from an ncurses interface, but it should be fairly self explanatory. Additionally, you will likely want to install the mailutils package to provide the standard system mail commands. $apt install mailutils Note: The mailutils package is required for the verification step at the end of this tutorial. ","date":"2020-05-24","objectID":"/posts/opensmtpd_ubuntu/:1:1","tags":["2FA","Email","GMail","Linux","OpenSMTPD","OpenSMTPD6","SMTP","Ubuntu","Ubuntu2004"],"title":"OpenSMTPD Relay on Ubuntu","uri":"/posts/opensmtpd_ubuntu/"},{"categories":["Networking"],"content":"ConfigureGrab your email account’s password. For my use case, I was using a GMail account which required two-factor authentication. Because of this, I had to use an App Password instead of my regular password. For any GMail users in a similar situation, instructions on how to generate an App Password can be found here. The default configuration file only requires a couple of minor tweaks. The gist of the configuration is to relay all mail originating from the local machine to a GMail account. /etc/smtpd.conf # $OpenBSD: smtpd.conf,v 1.10 2018/05/24 11:40:17 gilles Exp $ # This is the smtpd server system-wide configuration file. # See smtpd.conf(5) for more information. table secrets file:/etc/mail/secrets 1 table aliases file:/etc/aliases # To accept external mail, replace with: listen on all # listen on localhost action \"local\" maildir alias \u003caliases\u003e action \"relay\" relay host smtp+tls://jdoe@smtp.gmail.com:587 auth \u003csecrets\u003e 2 # Uncomment the following to accept external mail for domain \"example.org\" # # match from any for domain \"example.org\" action \"local\" match for local action \"local\" match from local for any action \"relay\"Use the content of the file /etc/mail/secrets, shown below, for the secrets table.The rule to forward all mail to GMail’s SMTP server using TLS. Your account credentials must be associated with a label in the /etc/mail/secrets file. Create the secrets file. $mkdir /etc/mail $touch /etc/mail/secrets Now, make sure the file’s permissions are tight before putting your plain-text password inside. $chmod 640 /etc/mail/secrets 1 $chown root:opensmtpd /etc/mail/secrets 2Permit read and write access for the file’s owner and read access for the file’s group.Set the file’s ownership such that it belongs to the root user and opensmtpd group. The following example illustrates the file format. /etc/mail/secrets jdoe jdoe@gmail.com:my_app_password 1Use the label jdoe to represent the account jdoe at gmail.com which has the passphrase my_app_password. Check that the OpenSMTPD configuration file is valid. $smtpd -n configuration OK Restart OpenSMTPD to make sure the configuration changes take effect. $systemctl restart opensmtpd Enable OpenSMTPD on system startup, if desired. $systemctl enable opensmtpd ","date":"2020-05-24","objectID":"/posts/opensmtpd_ubuntu/:1:2","tags":["2FA","Email","GMail","Linux","OpenSMTPD","OpenSMTPD6","SMTP","Ubuntu","Ubuntu2004"],"title":"OpenSMTPD Relay on Ubuntu","uri":"/posts/opensmtpd_ubuntu/"},{"categories":["Networking"],"content":"VerifyTo test the configuration, you can send an email from your computer and check if the email appears in the receiving account. Send a test email using the mail command from the mailutils package. $ echo \"Does it work?\" | mail -s \"OpenSMTPD Test Email\" test@example.com If everything works, you should receive an email at the designated address. ","date":"2020-05-24","objectID":"/posts/opensmtpd_ubuntu/:1:3","tags":["2FA","Email","GMail","Linux","OpenSMTPD","OpenSMTPD6","SMTP","Ubuntu","Ubuntu2004"],"title":"OpenSMTPD Relay on Ubuntu","uri":"/posts/opensmtpd_ubuntu/"},{"categories":["Networking"],"content":"Configuring IPv6 on my OpenBSD home router was a much more difficult task than I’d expected. While this was mostly due to the steep learning curve of IPv6 and DHCPv6, OpenBSD doesn’t provide DHCPv6 support in its native DHCP daemon. I’ve documented my setup and difficulties here in the hope it saves some time for someone else. ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:0:0","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"ConfigurationI configured IPv6 on on my home router running OpenBSD 6.7. ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:0","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"PFIPv6 packets need to get through the firewall for anything to happen. Below are snippets of my IPv6 packet-filter rules to allow the necessary traffic. /etc/pf.conf table \u003cmartians\u003e { 1 0.0.0.0/8 127.0.0.0/8 169.254.0.0/16 172.16.0.0/12 192.0.0.0/24 \\ 192.0.2.0/24 224.0.0.0/3 192.168.0.0/16 198.18.0.0/15 198.51.100.0/24 \\ 203.0.113.0/24 \\ ::/128 ::/96 ::1/128 ::ffff:0:0/96 100::/64 2001:10::/28 2001:2::/48 \\ 2001:db8::/32 3ffe::/16 fec0::/10 fc00::/7 } ... pass out inet6 2 pass in on { secure_lan insecure_lan } inet6 block in on egress from any to \u003cmartians\u003e pass in on egress inet6 proto udp from fe80::/10 port dhcpv6-server \\ to fe80::/10 port dhcpv6-client no state 3 pass out on egress inet6 proto udp from any to any port 33433 \u003e\u003c 33626 keep state 4 pass on any inet6 proto icmp6 all pass on secure_lan from secure_lan:network to secure_lan:network pass on insecure_lan from insecure_lan:network to insecure_lan:networkUpdate the martians table with IPv6 addresses.Allow IPv6 traffic.Allow DHCPv6 traffic between link-local IPv6 addresses.Allow ICMPv6 traffic. ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:1","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"DHCPv6There are two ways to obtain IPv6 address blocks: SLAAC and DHCPv6. At first, I tried to configure my external interface with OpenBSD’s IPv6 auto-configuration. I successfully received a globally reachable /64 block. Of course, my ISP only supplies dynamic IPv6 addresses. This put me in a pickle. How do I dynamically assign address blocks to my internal interfaces? How do I use SLAAC to configure my host machines when SLAAC requires a /64 subnet for the internal interface? It took me a while to realize I needed DHCPv6 to request multiple /64 blocks from my ISP and assign them to my internal network interfaces. OpenBSD has yet to natively support DHCPv6, so a third-party package was required. I decided on dhcpcd. There is a package available for wide-dhcpv6, but it lacks rc init scripts to conveniently integrate into the system’s startup process. pkg_add dhcpcd Configuration of dhcpcd was done in /etc/dhcpcd.conf. The default configuration required only a few changes, detailed below. /etc/dhcpcd.conf ipv6only 1 noipv6rs 2 waitip 6 3 allowinterfaces em0 em1 em2 em3 em4 em5 vlan2 4 interface em0 5 ipv6rs 6 ia_na 1 7 ia_pd 2 em1/0 em2/1 em3/2 em4/3 em5/4 vlan2/5 8Enable DHCP services for IPv6 only.Disable IPv6 router solicitation on all interfaces.Wait for an IPv6 address to be assigned before forking to the background.Allow touching these interfaces.Configure my external interface em0.Enable router solicitation on em0.Obtain a normal IPv6 address for em0.Request a prefix delegation for all of my internal interfaces. I then enabled the dhcpcd service at boot. rcctl enable dhcpcd ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:2","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"Router Advertisement DaemonOn OpenBSD, rad handles SLAAC on the LAN interfaces. Configuration of rad is done in rad.conf. /etc/rad.conf dns { nameserver { 2606:4700:4700::1111 2606:4700:4700::1001 } } interface em1 interface em2 interface em3 interface em4 interface em5 interface vlan2 Router advertisements will be issued on the listed interfaces. Along with the router advertisements, each interface will advertize the DNS nameservers configured globally at the top of the file. These are Cloudflare’s IPv6 DNS nameservers, in this instance. This is quite handy as clients can receive everything they need to connect to the internet. Without the DNS servers, a host would need to obtain nameservers through IPv4 DHCP or else configure their DNS servers manually. Ideally, my setup would have used my local Unbound instance for IPv6 DNS lookups, but I haven’t quite figured out how to handle that yet. Specifically, I’m at a loss for how to dynamically assign an IPv6 address to the Unbound server. I enabled rad to start at boot. rcctl enable rad ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:3","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"UnboundWhile I did not bind Unbound to any public IPv6 addresses, it can still do IPv6 DNS lookups. I enabled IPv6 support on Unbound and provided upstream IPv6 DNS servers. /var/unbound/etc/unbound.conf server: interface: 192.168.1.1 interface: 192.168.2.1 interface: 192.168.3.1 interface: 192.168.4.1 interface: 192.168.5.1 interface: 192.168.6.1 interface: 127.0.0.1 #interface: 127.0.0.1@5353 # listen on alternative port interface: ::1 do-ip6: yes prefer-ip6: yes access-control: ::0/0 refuse access-control: ::1 allow access-control: fd00::/8 allow access-control: fe80::/10 allow # Use an upstream forwarder (recursive resolver) for some or all zones. # forward-zone: name: \".\" # use for ALL queries forward-addr: 2606:4700:4700::1111 forward-addr: 2606:4700:4700::1001 forward-addr: 1.1.1.1 forward-addr: 1.0.0.1 ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:4","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"Prefer IPv6I configured my router to prefer using IPv6 over IPv4. /etc/resolv.conf.tail family inet6 inet4 ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:5","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"IPv6 RoutingOf course, I enabled IPv6 routing. /etc/sysctl.conf net.inet6.ip6.forwarding=1 ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:1:6","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"DeploymentLast of all, the system was rebooted to put all the changes in to take effect. reboot ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:2:0","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"VerificationOnce my router had rebooted, I ran ifconfig to ensure that my interfaces had public IPv6 addresses. ifconfig The resultant output is below. The details have been modified for privacy. At first, I noticed that some interfaces were not showing public IPv6 address assignments. They only had link-local IPv6 addresses, i.e. addresses beginning with 'fe80::'. I thought that dhcpcd was not provisioning addresses correctly. Eventually, I realized that public IPv6 addresses are only shown for interfaces with active connections. em0: flags=808843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST,AUTOCONF4\u003emtu 1500 lladdr 00:00:00:00:00:00 index 1 priority 0 llprio 3 groups: egress media: Ethernet autoselect (1000baseT full-duplex,rxpause,txpause) status: active inet 123.45.67.253 netmask 0xffffff00 broadcast 123.45.67.255 inet6 fe80::%em0 prefixlen 64 scopeid 0x1 inet6 2001:DB8:face:cafe:abcd:1111:2222:33 prefixlen 64 autoconf pltime 604473 vltime 2591673 em1: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:01 index 2 priority 0 llprio 3 groups: secure_lan media: Ethernet autoselect (1000baseT full-duplex,rxpause,txpause) status: active inet 192.168.1.1 netmask 0xffffff00 broadcast 192.168.1.255 inet6 fe80::0001%em1 prefixlen 64 scopeid 0x2 em2: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:02 index 3 priority 0 llprio 3 groups: secure_lan media: Ethernet autoselect (100baseTX full-duplex) status: active inet 192.168.2.1 netmask 0xffffff00 broadcast 192.168.2.255 inet6 fe80::1%em2 prefixlen 64 scopeid 0x3 inet6 2001:DB8:face:cafe:1::1 prefixlen 64 pltime 205171 vltime 231091 em3: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:02 index 4 priority 0 llprio 3 groups: secure_lan media: Ethernet autoselect (none) status: no carrier inet 192.168.3.1 netmask 0xffffff00 broadcast 192.168.3.255 inet6 fe80::2%em3 prefixlen 64 scopeid 0x4 em4: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:03 index 5 priority 0 llprio 3 groups: secure_lan media: Ethernet autoselect (1000baseT full-duplex,master,rxpause,txpause) status: active inet 192.168.4.1 netmask 0xffffff00 broadcast 192.168.4.255 inet6 fe80::3%em4 prefixlen 64 scopeid 0x5 inet6 2001:DB8:face:cafe:3::1 prefixlen 64 pltime 205172 vltime 231092 em5: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:04 index 6 priority 0 llprio 3 groups: secure_lan media: Ethernet autoselect (none) status: no carrier inet 192.168.5.1 netmask 0xffffff00 broadcast 192.168.5.255 inet6 fe80::4%em5 prefixlen 64 scopeid 0x6 vlan2: flags=8843\u003cUP,BROADCAST,RUNNING,SIMPLEX,MULTICAST\u003emtu 1500 lladdr 00:00:00:00:00:05 index 9 priority 0 llprio 3 encap: vnetid 2 parent em1 txprio packet rxprio outer groups: vlan insecure_lan media: Ethernet autoselect (1000baseT full-duplex,rxpause,txpause) status: active inet 192.168.6.1 netmask 0xffffff00 broadcast 192.168.6.255 inet6 fe80::5%vlan2 prefixlen 64 scopeid 0x9 inet6 2001:DB8:face:cafe:5::1 prefixlen 64 pltime 205172 vltime 231092 To make sure end-to-end connections were working over IPv6, I pinged Cloudflare's DNS server from my laptop. ping6 2606:4700:4700::1111 ","date":"2020-05-23","objectID":"/posts/openbsd_ipv6/:3:0","tags":["BSD","DHCPCD","DHCPv6","Firewall","IPv6","OpenBSD","OpenBSD6","OpenBSD67","PF"],"title":"IPv6 on OpenBSD","uri":"/posts/openbsd_ipv6/"},{"categories":["Networking"],"content":"Blocking connections to nefarious IP addresses in your firewall is usually a good idea. On OpenBSD, the pf-badhost script updates PF to block traffic to and from such addresses. This post walks through my installation and verification of pf-badhost. Make sure to check out the well-written installation instructions, too. ","date":"2020-04-04","objectID":"/posts/pf_badhost/:0:0","tags":["BSD","Firewall","OpenBSD","OpenBSD6","OpenBSD67","PF","pf-badhost"],"title":"PF Badhost","uri":"/posts/pf_badhost/"},{"categories":["Networking"],"content":"ConfigureDownload the pf-badhost.sh script. ftp https://www.geoghegan.ca/scripts/pf-badhost.sh Install the script with the appropriate permissions. install -g bin -m 644 -o root pf-badhost.sh /usr/local/bin/ 1 The script will be owned by root, belong to the bin group, and be readable by everyone and writeable by the owner. Create a new user, _pfbadhost, who will not be allowed to login. useradd -s /sbin/nologin _pfbadhost Install an empty pf-badhost.txt file owned by the _pfbadhost user which is readable and writeable by the owner only. install -m 600 -o _pfbadhost /dev/null /etc/pf-badhost.txt Give the necessary permissions to the _pfbadhost user. /etc/doas.conf permit nopass _pfbadhost cmd pfctl args -nf /etc/pf.conf 1 permit nopass _pfbadhost cmd pfctl args -t pfbadhost -T replace -f /etc/pf-badhost.txt 2Allow _pfbadhost to reload the PF configuration file without a password.Allow _pfbadhost to update the pfbadhost PF table from the file /etc/pf-badhost.txt. Edit the crontab file for _pfbadhost. crontab -u _pfbadhost -e Add a rule to run the pf-badhost.sh script every morning at 6:45. /var/cron/tabs/_pfbadhost # use /bin/sh to run commands, no matter what /etc/passwd says SHELL=/bin/sh # Update pf-badhost at 6:45 every morning. 45 6 * * * /usr/local/bin/pf-badhost.sh Run the pf-badhost.sh script. doas -u _pfbadhost sh /usr/local/bin/pf-badhost.sh Configure PF to block all traffic to or from the blacklisted addresses. /etc/pf.conf # pf-badhost configuration table \u003cpfbadhost\u003e persist file “/etc/pf-badhost.txt” 1 block in quick on egress from \u003cpfbadhost\u003e 2 block out quick on egress to \u003cpfbadhost\u003e 3Populate the pfbadhost table from the file /etc/pf-badhost.txt and keep the table even if no rules refer to it.Block any traffic coming in to the gateway from any address in the pfbadhost table.Block any traffic coming out of the gateway to any address in the pfbadhost table. Note: Be careful not to block your internal network’s traffic here. Reload the PF ruleset. pfctl -f /etc/pf.conf Following the original tutorial, run the pf-badhost.sh script once more for good measure. doas -u _pfbadhost sh /usr/local/bin/pf-badhost.sh ","date":"2020-04-04","objectID":"/posts/pf_badhost/:1:0","tags":["BSD","Firewall","OpenBSD","OpenBSD6","OpenBSD67","PF","pf-badhost"],"title":"PF Badhost","uri":"/posts/pf_badhost/"},{"categories":["Networking"],"content":"VerifyNow…​ did that actually do anything? I usually ask myself this question, and I like to be sure sometimes, especially when it comes to network security. ","date":"2020-04-04","objectID":"/posts/pf_badhost/:2:0","tags":["BSD","Firewall","OpenBSD","OpenBSD6","OpenBSD67","PF","pf-badhost"],"title":"PF Badhost","uri":"/posts/pf_badhost/"},{"categories":["Networking"],"content":"OutboundFirst, test the outbound traffic destined for a blocked IP address. For the outbound test, you could use any publicly available IP address which is not blacklisted. I use the address of one of Google’s DNS servers, 8.8.8.8 in this test. Note: You could just ping a blacklisted server with and without the pfbadhost rules in place. I definitely did this on my first go. 😊 However, I figured that probably wasn’t the best idea and so devised a safer test. Make sure that the server is reachable before adding it to the blacklist. ping -c 3 8.8.8.8 There should be zero percent packet loss if everything went well, like in the following output. PING 8.8.8.8 (8.8.8.8): 56 data bytes 64 bytes from 8.8.8.8: icmp_seq=0 ttl=52 time=9.906 ms 64 bytes from 8.8.8.8: icmp_seq=1 ttl=52 time=9.736 ms 64 bytes from 8.8.8.8: icmp_seq=2 ttl=52 time=10.039 ms --- 8.8.8.8 ping statistics --- 3 packets transmitted, 3 packets received, 0.0% packet loss round-trip min/avg/max/std-dev = 9.736/9.894/10.039/0.124 ms If the packets don’t reach the server successfully, you’ll have to troubleshoot. A PF rule could be blocking outgoing traffic to the server. Hopefully the server your testing against isn’t already on the blacklist. Now, add the server`s IP address to the blacklist. /etc/pf-badhost.txt # User Defined Rules: 8.8.8.8 Update the table by reloading PF. pfctl -f /etc/pf.conf Now, verify that the server is no longer reachable. ping -c 50 8.8.8.8 This should take a minute and not have any successful pings. Your output should match the following, accounting for the IP address you selected. PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. --- 8.8.8.8 ping statistics --- 50 packets transmitted, 0 received, 100% packet loss, time 50168ms This means pf-badhost is successfully blocking traffic outbound to this blacklisted IP address. Remember to remove 8.8.8.8 from the list and reload the PF ruleset once again. ","date":"2020-04-04","objectID":"/posts/pf_badhost/:2:1","tags":["BSD","Firewall","OpenBSD","OpenBSD6","OpenBSD67","PF","pf-badhost"],"title":"PF Badhost","uri":"/posts/pf_badhost/"},{"categories":["Networking"],"content":"InboundVerifying the inbound traffic is not as straightforward. My AWS server allows me to test the ability of pf-badhost to block incoming traffic from blacklisted IP addresses. The IP address 1.2.3.4 represents the server. First, ensure you can ping the server before it is blacklisted. I had to add a temporary rule to my PF configuration to allow the server to ping the router. /etc/pf.conf pass in on egress from 1.2.3.4 to any 1 # pf-badhost configuration table \u003cpfbadhost\u003e persist file “/etc/pf-badhost.txt” block in quick on egress from \u003cpfbadhost\u003e block out quick on egress to \u003cpfbadhost\u003eAllow traffic to the router from the server. To account for the new rule, reload the PF ruleset. pfctl -f /etc/pf.conf The IP address 2.2.2.2 will represent the router’s gateway address. From the server, ping the router. ping -c 3 2.2.2.2 It should be able to ping the server, assuming the server is not one of the blacklisted IPs or impeded by a firewall rule. Successful output should look like the following. PING 2.2.2.2 (2.2.2.2): 56 data bytes 64 bytes from 2.2.2.2: icmp_seq=0 ttl=52 time=9.906 ms 64 bytes from 2.2.2.2: icmp_seq=1 ttl=52 time=9.736 ms 64 bytes from 2.2.2.2: icmp_seq=2 ttl=52 time=10.039 ms --- 2.2.2.2 ping statistics --- 3 packets transmitted, 3 packets received, 0.0% packet loss round-trip min/avg/max/std-dev = 9.736/9.894/10.039/0.124 ms Now, Add the IP address of the server to /etc/pf-badhost.txt /etc/pf-badhost.txt # User Defined Rules: 1.2.3.4 Update the table by reloading PF. pfctl -f /etc/pf.conf From the server, ping the router again. ping -c 50 2.2.2.2 The packets should all be dropped, printing the output below. PING 2.2.2.2 (2.2.2.2) 56(84) bytes of data. --- 2.2.2.2 ping statistics --- 50 packets transmitted, 0 received, 100% packet loss, time 50168ms To clean up, remove the server’s IP from the blacklist and reload PF. If applicable, remember to delete the temporary rule in /etc/pf.conf if you added it. ","date":"2020-04-04","objectID":"/posts/pf_badhost/:2:2","tags":["BSD","Firewall","OpenBSD","OpenBSD6","OpenBSD67","PF","pf-badhost"],"title":"PF Badhost","uri":"/posts/pf_badhost/"},{"categories":["Networking"],"content":"Ever want to enable DNSSEC on your Unbound OpenBSD 6.6 server? Me too! Using this article as a guide, I document the process. ","date":"2020-03-28","objectID":"/posts/unbound_dnssec/:0:0","tags":["BSD","DNS","DNSSEC","OpenBSD","OpenBSD6","OpenBSD66","Unbound"],"title":"DNSSEC with Unbound","uri":"/posts/unbound_dnssec/"},{"categories":["Networking"],"content":"Unbound ConfigurationUse the ftp command to download the Root Hints. ftp -o /var/unbound/etc/root.hints https://www.internic.net/domain/named.root Download the trust anchor file with the unbound-anchor utility. unbound-anchor Configure unbound.conf. Add the location of the root.hints file and uncomment the lines with the keys auto-trust-anchor-file and val-log-level. /var/unbound/etc/unbound.conf # Uncomment to enable DNSSEC validation. # root-hints: \"/var/unbound/etc/root.hints\" 1 auto-trust-anchor-file: \"/var/unbound/db/root.key\" val-log-level: 2This line was added, not uncommented…​ to be fair. Note: Make sure the upstream resolvers support DNSSEC. The list provided by DNSCrypt has some good options. # Use an upstream forwarder (recursive resolver) for some or all zones. # forward-zone: name: \".\" # use for ALL queries forward-addr: 176.103.130.132 # adguard-dns-family forward-addr: 185.228.168.10 # cleanbrowsing-adult Verify the configuration of unbound.conf which unbound-checkconf. unbound-checkconf Finally, restart Unbound. rcctl restart unbound Verify that DNSSEC is working with the dig command from a computer using your unbound server. This website, jwillikers.com, has DNSSEC enabled and so makes for a good address to test. Cloudflare provides a nice write-up about using dig to verify DNSSEC here. dig jwillikers.com +dnssec The example below contains the appropriate response with DNSSEC enabled. Look for the ad flag and the RRSIG entry. ; \u003c\u003c\u003e\u003e DiG 9.11.5-P4-5.1ubuntu2.1-Ubuntu \u003c\u003c\u003e\u003e jwillikers.com +dnssec ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 46922 ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags: do; udp: 4096 ;; QUESTION SECTION: ;jwillikers.com. IN A ;; ANSWER SECTION: jwillikers.com. 300 IN A 104.28.26.241 jwillikers.com. 300 IN A 104.28.27.241 jwillikers.com. 300 IN RRSIG A 13 2 300 20200329192309 20200327172309 34505 jwillikers.com. DcQzhWhlVflaeqCkZn92X6jRMJvtFySr7wN1AzGaJVk7/b4JbS/lqqZB ZepEA6FP3bHz8g5H6zduVKKv/D8Tqg== 2 ;; Query time: 35 msec ;; SERVER: 192.168.6.1#53(192.168.6.1) ;; WHEN: Sat Mar 28 13:23:09 CDT 2020 ;; MSG SIZE rcvd: 185The ad flag is present in the list of flags.The RRSIG entry. ","date":"2020-03-28","objectID":"/posts/unbound_dnssec/:1:0","tags":["BSD","DNS","DNSSEC","OpenBSD","OpenBSD6","OpenBSD66","Unbound"],"title":"DNSSEC with Unbound","uri":"/posts/unbound_dnssec/"},{"categories":["Networking"],"content":"Ever want to get rid of all those annoying internet ads? Me too. I’d been planning on using something like Pi-hole, but recently stumbled upon unbound-adblock, which is perfect for my OpenBSD home router. The setup is very well-documented there, but I provide my own, slightly-modified setup instructions here. Most notably, the cron-job runs at 6:30 AM, not midnight, and I refined the PF rule which redirects DNS requests to Google’s DNS servers. ","date":"2020-03-28","objectID":"/posts/unbound_adblock/:0:0","tags":["Adblock","BSD","DNS","OpenBSD","OpenBSD6","OpenBSD67","Pihole","Unbound","unbound-adblock"],"title":"Unbound Adblock","uri":"/posts/unbound_adblock/"},{"categories":["Networking"],"content":"PrepareFirst, set your expectations. Get a base-line of what ads should be blocked by working through the test steps on https://ads-blocker.com/testing. Note: Disable any browser-based ad-blockers you might have enabled, otherwise you won’t be able to verify your setup actually blocks ads. ","date":"2020-03-28","objectID":"/posts/unbound_adblock/:1:0","tags":["Adblock","BSD","DNS","OpenBSD","OpenBSD6","OpenBSD67","Pihole","Unbound","unbound-adblock"],"title":"Unbound Adblock","uri":"/posts/unbound_adblock/"},{"categories":["Networking"],"content":"ConfigureDownload the unbound-adblock.sh script. ftp https://www.geoghegan.ca/scripts/unbound-adblock.sh Install the script with the appropriate permissions. install -g bin -m 644 -o root unbound-adblock.sh /usr/local/bin/ 1 The script will be owned by root, belong to the bin group, and be readable by everyone and writeable by the owner. Create a new user, _adblock, who will not be allowed to login. useradd -s /sbin/nologin _adblock Install an empty adblock.conf file owned by the _adblock user which is readable by everyone but only writeable by the owner. install -m 644 -o _adblock /dev/null /var/unbound/etc/adblock.conf Include the adblock.conf file at the end of the server section. /var/unbound/etc/unbound.conf server: ... # Include the unbound-adblock configuration file. include: /var/unbound/etc/adblock.conf Allow the _adblock user to reload the unbound service without requiring a password. /etc/doas.conf # Allow the unbound-adblock user / script to reload the unbound service. permit nopass _adblock cmd rcctl args reload unbound Edit the _adblock users crontab file. crontab -u _adblock -e Add a rule to run the unbound-adblock.sh script every morning at 6:30. /var/cron/tabs/_adblock # use /bin/sh to run commands, no matter what /etc/passwd says SHELL=/bin/sh # Update unbound-adblock at 6:30 every morning. 30 6 * * * /usr/local/bin/unbound-adblock.sh Run the unbound-adblock.sh script once. doas -u _adblock sh /usr/local/bin/unbound-adblock.sh Restart the unbound service. rcctl restart unbound Add a PF rule to redirect all DNS queries bound for Google’s DNS servers, 8.8.8.8 and 8.8.4.4 to your unbound DNS server, i.e. 192.168.1.1. The example below uses a macro lan_if to represent the LAN network interface, em1. /etc/pf.conf # Redirect any DNS requests to Google's DNS servers to the LAN's unbound server. lan_if = \"em1\" lan_dns_server = 192.168.1.1 table \u003cgoogle_dns_servers\u003e { 8.8.8.8 8.8.4.4 } ... pass in quick on $lan_if quick inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan_dns_server port domain Note: Be careful to position this rule in a place where it is not superceded by a preceding quick rule. My actual configuration is a bit more complex, but I have included it here for reference. /etc/pf.conf lan1_if = \"em1\" lan2_if = \"em2\" lan3_if = \"em3\" lan4_if = \"em4\" lan5_if = \"em5\" secure_wifi_if = \"vlan2\" guest_wifi_if = \"vlan3\" lan1_dns_server = 192.168.1.1 lan2_dns_server = 192.168.2.1 lan3_dns_server = 192.168.3.1 lan4_dns_server = 192.168.4.1 lan5_dns_server = 192.168.5.1 secure_wifi_dns_server = 192.168.6.1 guest_wifi_dns_server = 192.168.7.1 table \u003cgoogle_dns_servers\u003e { 8.8.8.8 8.8.4.4 } ... pass in quick on $lan1_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan1_dns_server port domain pass in quick on $lan2_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan2_dns_server port domain pass in quick on $lan3_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan3_dns_server port domain pass in quick on $lan4_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan4_dns_server port domain pass in quick on $lan5_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $lan5_dns_server port domain pass in quick on $secure_wifi_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $secure_wifi_dns_server port domain pass in quick on $guest_wifi_if inet proto { tcp udp } to \u003cgoogle_dns_servers\u003e port domain rdr-to $guest_wifi_dns_server port domain ... Reload the updated PF rules. pfctl -f /etc/pf.conf ","date":"2020-03-28","objectID":"/posts/unbound_adblock/:2:0","tags":["Adblock","BSD","DNS","OpenBSD","OpenBSD6","OpenBSD67","Pihole","Unbound","unbound-adblock"],"title":"Unbound Adblock","uri":"/posts/unbound_adblock/"},{"categories":["Networking"],"content":"VerifyTest your new-found adblocking by revisiting the test steps. Those pesky ads should have mystically vanished. ","date":"2020-03-28","objectID":"/posts/unbound_adblock/:3:0","tags":["Adblock","BSD","DNS","OpenBSD","OpenBSD6","OpenBSD67","Pihole","Unbound","unbound-adblock"],"title":"Unbound Adblock","uri":"/posts/unbound_adblock/"},{"categories":["Networking"],"content":"Some ISP’s establish connections with their customers' networks through PPPoE. I recently setup an OpenBSD 6.6 router which required PPPoE. This is my story. ","date":"2020-03-12","objectID":"/posts/pppoe_openbsd/:0:0","tags":["BSD","OpenBSD","OpenBSD6","OpenBSD66","PPPoE"],"title":"PPPoE on OpenBSD","uri":"/posts/pppoe_openbsd/"},{"categories":["Networking"],"content":"DNS ServersIf necessary, configure your system to use your preferred DNS nameservers. Tip: A common way of connecting to your ISP’s network is through DHCP. DHCP is capable of providing your system with DNS nameservers according to RFC 2132 and RFC 2937. To my knowledge, this capability is absent from the PPPoE Specification. If you are switching from DHCP to PPPoE, be mindful that you may need to set your nameservers if you have not explicitly done so. The place to do this is resolv.conf. My system uses a couple of nameservers from the list provided by DNSCrypt. The Google nameservers are also quite popular. /etc/resolv.conf nameserver 176.103.130.132 1 nameserver 185.228.168.10 2adguard-dns-familycleanbrowsing-adult ","date":"2020-03-12","objectID":"/posts/pppoe_openbsd/:1:0","tags":["BSD","OpenBSD","OpenBSD6","OpenBSD66","PPPoE"],"title":"PPPoE on OpenBSD","uri":"/posts/pppoe_openbsd/"},{"categories":["Networking"],"content":"PPPoE ConfigurationThe configuration is fairly straightforward. I use a hostname.if file to initialize the PPPoE interface when the system boots. This example is very similar to the jumbo frames example provided in the PPPOE(4) manpage. Because this is a router, it requires more than the basic setup. PPPoE has an overhead and the incoming LAN connections will not be aware of this. My modifications to the example are as follows. First, chap replaces pap as the authentication protocol. Second, only IPv4 options are present since my ISP doesn’t support IPv6. /etc/hostname.pppoe0 inet 0.0.0.0 255.255.255.255 NONE mtu 1500 \\ 1 pppoedev em0 authproto chap \\ 2 authname 'username' authkey 'password' up dest 0.0.0.1 !/sbin/route add default -ifp pppoe0 0.0.0.1Set the IP to 0.0.0.0, a wildcard representing whatever IP the PPPoE connection provides, and adjust the frame size.em0 is the ethernet interface for the router’s WAN port. The physical em0 interface must be up. /etc/hostname.em0 up mtu 1508 Start up the em0 and pppoe0 interfaces. sh /etc/netstart em0 pppoe0 Caution: The /etc/netstart script was not able to successfully establish a PPPoE connection when I changed my configuration from pap to chap. I had to reboot my system after changing the configuration file for the connection to succeed. reboot ","date":"2020-03-12","objectID":"/posts/pppoe_openbsd/:2:0","tags":["BSD","OpenBSD","OpenBSD6","OpenBSD66","PPPoE"],"title":"PPPoE on OpenBSD","uri":"/posts/pppoe_openbsd/"}]